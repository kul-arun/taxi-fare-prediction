{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0557197-f75d-4fe2-acc5-19e422aa53d6",
   "metadata": {},
   "source": [
    "# New York City Taxi Fare Prediction\n",
    "\n",
    "In this project, we shall work with a past Kaggle Playground competition called the [New York City Taxi Fare Prediction](https://www.kaggle.com/competitions/new-york-city-taxi-fare-prediction). A subset of the original dataset has been taken from DataCamp to reduce the data size. The [dataset](https://assets.datacamp.com/production/repositories/4443/datasets/1abe6ab7c7c0e880a2f6febcae946a33a9ef5e31/taxi_train_chapter_4.csv) is located in the `data` directory.\n",
    "\n",
    "The aim of the competition is to predict the fare amount of a taxi ride in New York City using the given information about the number of passengers and the pickup and drop off locations. The evaluation metric for this competition is the root mean-squared error (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a795ad9-850e-42cd-a7ec-7aa0c7e6e382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a2ea2-413c-4fb5-b7d9-39e9ae29f0da",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6efd1f28-b2b0-491c-a516-1d450e48b5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20000 entries, 0 to 19999\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   fare_amount        20000 non-null  float64\n",
      " 1   pickup_datetime    20000 non-null  object \n",
      " 2   pickup_longitude   20000 non-null  float64\n",
      " 3   pickup_latitude    20000 non-null  float64\n",
      " 4   dropoff_longitude  20000 non-null  float64\n",
      " 5   dropoff_latitude   20000 non-null  float64\n",
      " 6   passenger_count    20000 non-null  int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/taxi_data.csv\", index_col=\"id\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fa5a06-50de-4b8d-8c1a-be2963c772ab",
   "metadata": {},
   "source": [
    "Let us look at the summary statistics of the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64560cd1-4e15-4a91-b780-544b38bbdf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.303321</td>\n",
       "      <td>-72.478584</td>\n",
       "      <td>39.921043</td>\n",
       "      <td>-72.497221</td>\n",
       "      <td>39.913606</td>\n",
       "      <td>1.658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.541637</td>\n",
       "      <td>10.525376</td>\n",
       "      <td>6.678592</td>\n",
       "      <td>10.460530</td>\n",
       "      <td>6.139231</td>\n",
       "      <td>1.283674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-74.438233</td>\n",
       "      <td>-74.006893</td>\n",
       "      <td>-84.654241</td>\n",
       "      <td>-74.006377</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>-73.992150</td>\n",
       "      <td>40.734706</td>\n",
       "      <td>-73.991224</td>\n",
       "      <td>40.734537</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>-73.981711</td>\n",
       "      <td>40.752680</td>\n",
       "      <td>-73.980217</td>\n",
       "      <td>40.753583</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.500000</td>\n",
       "      <td>-73.966802</td>\n",
       "      <td>40.767443</td>\n",
       "      <td>-73.963729</td>\n",
       "      <td>40.768135</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>40.766125</td>\n",
       "      <td>401.083332</td>\n",
       "      <td>40.802437</td>\n",
       "      <td>41.366138</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "count  20000.000000      20000.000000     20000.000000       20000.000000   \n",
       "mean      11.303321        -72.478584        39.921043         -72.497221   \n",
       "std        9.541637         10.525376         6.678592          10.460530   \n",
       "min       -3.000000        -74.438233       -74.006893         -84.654241   \n",
       "25%        6.000000        -73.992150        40.734706         -73.991224   \n",
       "50%        8.500000        -73.981711        40.752680         -73.980217   \n",
       "75%       12.500000        -73.966802        40.767443         -73.963729   \n",
       "max      180.000000         40.766125       401.083332          40.802437   \n",
       "\n",
       "       dropoff_latitude  passenger_count  \n",
       "count      20000.000000     20000.000000  \n",
       "mean          39.913606         1.658000  \n",
       "std            6.139231         1.283674  \n",
       "min          -74.006377         0.000000  \n",
       "25%           40.734537         1.000000  \n",
       "50%           40.753583         1.000000  \n",
       "75%           40.768135         2.000000  \n",
       "max           41.366138         6.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443c30d2-52ba-41e9-b424-6ab325bedd07",
   "metadata": {},
   "source": [
    "We can observe that the minimum `fare_amount` value is negative and the minimum `passenger_count` is 0. Let us remove all the rows in the dataset where the aforementioned columns are non-positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d863229-930f-4a5f-b0df-2b3eade5599f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19921 entries, 0 to 19999\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   fare_amount        19921 non-null  float64\n",
      " 1   pickup_datetime    19921 non-null  object \n",
      " 2   pickup_longitude   19921 non-null  float64\n",
      " 3   pickup_latitude    19921 non-null  float64\n",
      " 4   dropoff_longitude  19921 non-null  float64\n",
      " 5   dropoff_latitude   19921 non-null  float64\n",
      " 6   passenger_count    19921 non-null  int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df[(df[\"fare_amount\"] > 0) & (df[\"passenger_count\"] > 0)]\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23151358-78e3-4158-b66d-ec23536661e6",
   "metadata": {},
   "source": [
    "There no missing values in the dataset. The `fare_amount` column is the target variable and the rest of the columns are the features. Let us inspect the top 5 rows of the `pickup_datetime` column whose datatype is `object`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b48f3ad9-1b34-44da-afe4-443772bc381d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0    2009-06-15 17:26:21 UTC\n",
       "1    2010-01-05 16:52:16 UTC\n",
       "2    2011-08-18 00:35:00 UTC\n",
       "3    2012-04-21 04:30:42 UTC\n",
       "4    2010-03-09 07:51:00 UTC\n",
       "Name: pickup_datetime, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"pickup_datetime\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d7189-3da2-41cc-8d92-54dfcd75f3d4",
   "metadata": {},
   "source": [
    "We shall convert the column to a pandas `datetime` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b4bbf22-cfab-42c9-8daf-bd438c09f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pickup_datetime\"] = pd.to_datetime(df[\"pickup_datetime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c1c5f0-84b9-42f7-8c92-e9ab970c3d50",
   "metadata": {},
   "source": [
    "We shall now remove outliers in the coordinates of the pickup and dropoff locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41dcc3db-b1cb-4955-b1f2-0c6ad8709739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounds(x):\n",
    "    mean = x.mean()\n",
    "    std = x.std()\n",
    "    cut_off = 3*std\n",
    "    return mean-cut_off, mean+cut_off\n",
    "\n",
    "col_list = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']\n",
    "\n",
    "for col in col_list:\n",
    "    lower, upper = get_bounds(df[col])\n",
    "    df = df[(df[col] > lower) & (df[col] < upper)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c0fe28-5a9c-4ca2-97a1-41fb826fd853",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec76412-c6e8-4ec0-8571-15eed87ca8a9",
   "metadata": {},
   "source": [
    "Let us create new features by extracting details from the `pickup_datetime` column, and then drop the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57fa61d1-5d20-4613-82ca-9a3e5b9079f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hour\"] = df[\"pickup_datetime\"].dt.hour\n",
    "df[\"day_of_week\"] = df[\"pickup_datetime\"].dt.dayofweek\n",
    "df[\"month\"] = df[\"pickup_datetime\"].dt.month\n",
    "df[\"year\"] = df[\"pickup_datetime\"].dt.year\n",
    "\n",
    "df.drop(\"pickup_datetime\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca814e2-eb80-43f2-98e5-03db110c9cab",
   "metadata": {},
   "source": [
    "We can calculate the distance between the pickup and drop off location using the [haversine formula](https://en.wikipedia.org/wiki/Haversine_formula)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98899d01-fa6d-41c2-a619-8652bcaf75e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat_1, long_1, lat_2, long_2):\n",
    "    # average radius of earth in km.\n",
    "    r = 6371\n",
    "    lat_diff = lat_2 - lat_1\n",
    "    long_diff = long_2 - long_1\n",
    "    hav = np.square(np.sin(lat_diff/2)) + np.cos(lat_1)*np.cos(lat_2)*np.square(np.sin(long_diff/2))\n",
    "    return 2*r*np.arcsin(np.sqrt(hav))\n",
    "\n",
    "# convert from degrees to radians.\n",
    "df[\"pickup_latitude\"] = np.deg2rad(df[\"pickup_latitude\"])\n",
    "df[\"pickup_longitude\"] = np.deg2rad(df[\"pickup_longitude\"])\n",
    "df[\"dropoff_latitude\"] = np.deg2rad(df[\"dropoff_latitude\"])\n",
    "df[\"dropoff_longitude\"] = np.deg2rad(df[\"dropoff_longitude\"])\n",
    "\n",
    "df[\"distance (km)\"] = haversine_distance(df[\"pickup_latitude\"], df[\"pickup_longitude\"],\n",
    "                                         df[\"dropoff_latitude\"], df[\"dropoff_longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e820ac8d-6e02-4e2e-88ae-aa60afe298e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19508 entries, 0 to 19999\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   fare_amount        19508 non-null  float64\n",
      " 1   pickup_longitude   19508 non-null  float64\n",
      " 2   pickup_latitude    19508 non-null  float64\n",
      " 3   dropoff_longitude  19508 non-null  float64\n",
      " 4   dropoff_latitude   19508 non-null  float64\n",
      " 5   passenger_count    19508 non-null  int64  \n",
      " 6   hour               19508 non-null  int32  \n",
      " 7   day_of_week        19508 non-null  int32  \n",
      " 8   month              19508 non-null  int32  \n",
      " 9   year               19508 non-null  int32  \n",
      " 10  distance (km)      19508 non-null  float64\n",
      "dtypes: float64(6), int32(4), int64(1)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb37ab-0310-4300-85c8-938641bf0f77",
   "metadata": {},
   "source": [
    "All the columns are of numeric type. Let us split the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5c34497-af48-492a-b5b4-aecdbdb0d923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset has 15606 rows and the test dataset has 3902 rows.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# features.\n",
    "X = df.drop(\"fare_amount\", axis=1)\n",
    "# target.\n",
    "y = df[\"fare_amount\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "\n",
    "print(f\"The train dataset has {y_train.size} rows and the test dataset has {y_test.size} rows.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c784625-4a35-48b6-a35f-a26aa72316c5",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0100e9ad-4735-44d2-9068-fea0bc104bbc",
   "metadata": {},
   "source": [
    "We shall build a stacked model of a random forest regressor and a gradient boosting regressor. Let us first split the training set into 2 parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2847860-0838-4bac-a03d-d4bf34a5d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_train2, y_train1, y_train2 = train_test_split(X_train, y_train, test_size=0.5, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16480c64-e028-401a-87da-5b4c8fbacb9b",
   "metadata": {},
   "source": [
    "We shall train the base-models on the first part of the training dataset. The predictions made by the base-models are given as input to a meta-model, which then makes the final prediction. Let us now train the base-models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbbc629-9d22-41c9-b1fa-147aeef058cd",
   "metadata": {},
   "source": [
    "**Random Forest Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f87a21c5-b171-4c17-a944-87cca2c5ebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best values found are: {'max_depth': 8, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(random_state=21)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=21)\n",
    "\n",
    "rf_params = {'n_estimators': [100, 250, 500],\n",
    "             'max_depth': [3, 5, 8]}\n",
    "\n",
    "# find optimal hyperparameters.\n",
    "rf_cv = GridSearchCV(estimator=rf_model, param_grid=rf_params, cv=kf, n_jobs=-1,\n",
    "                     scoring='neg_root_mean_squared_error', refit=True)\n",
    "\n",
    "rf_cv.fit(X_train1, y_train1)\n",
    "\n",
    "print(f'The best values found are: {rf_cv.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ff24f-997f-4cdd-8ec3-8740c1dcb777",
   "metadata": {},
   "source": [
    "**Gradient Boosting Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acf82137-72d7-47b3-90b2-8b914c2ce26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best values found are: {'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "gb_model = GradientBoostingRegressor(random_state=21)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=21)\n",
    "\n",
    "gb_params = {'n_estimators': [50, 100, 200],\n",
    "             'max_depth': [2, 3, 5],\n",
    "             'subsample': [0.6, 0.7, 0.8]}\n",
    "\n",
    "# find optimal hyperparameters.\n",
    "gb_cv = GridSearchCV(estimator=gb_model, param_grid=gb_params, cv=kf, n_jobs=-1,\n",
    "                     scoring='neg_root_mean_squared_error', refit=True)\n",
    "\n",
    "gb_cv.fit(X_train1, y_train1)\n",
    "\n",
    "print(f'The best values found are: {gb_cv.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86e73c5-8031-4889-89e2-3ceee1e0a61d",
   "metadata": {},
   "source": [
    "**Predictions**\n",
    "\n",
    "Predictions are made by the base-models on the 2nd part of the training set, and we use them as features for making predictions with the meta-model. We have chosen a linear regression model with no intercept as the meta-model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4f9bbef-883d-4b7e-9503-566aeee5eb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross-validation score (RMSE) on the second part of the training set: 3.9073\n"
     ]
    }
   ],
   "source": [
    "rf_train2_pred = rf_cv.predict(X_train2)\n",
    "gb_train2_pred = gb_cv.predict(X_train2)\n",
    "\n",
    "X_train2_preds = np.column_stack((rf_train2_pred, gb_train2_pred))\n",
    "\n",
    "# meta model\n",
    "lr = LinearRegression(fit_intercept=False)\n",
    "\n",
    "lr.fit(X_train2_preds, y_train2)\n",
    "\n",
    "cv_score = -np.mean(cross_val_score(lr, X_train2_preds, y_train2, cv=kf, scoring='neg_root_mean_squared_error'))\n",
    "\n",
    "print(f'5-fold cross-validation score (RMSE) on the second part of the training set: {cv_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bed1de-040b-4004-b8ab-7449ac6190f9",
   "metadata": {},
   "source": [
    "**Stacked Model Evaluation**\n",
    "\n",
    "We evaluate the performance of the stacked model on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37bb2ce1-5bc8-4e1e-a228-c28878d51f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score on the test set: 4.7746\n"
     ]
    }
   ],
   "source": [
    "rf_test_pred = rf_cv.predict(X_test)\n",
    "gb_test_pred = gb_cv.predict(X_test)\n",
    "\n",
    "X_test_preds = np.column_stack((rf_test_pred, gb_test_pred))\n",
    "\n",
    "y_pred = lr.predict(X_test_preds)\n",
    "\n",
    "rmse= np.sqrt(np.mean(np.square(y_pred - y_test)))\n",
    "\n",
    "print(f'RMSE score on the test set: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f932a046-8642-4ab1-855f-30e8bcf2a77a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The stacked model performs really well and the RMSE value on the unseen test data is pretty low."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
